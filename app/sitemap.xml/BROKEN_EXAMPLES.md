# Broken Sitemap Examples - For Testing Only

## ‚ö†Ô∏è Test 1: Invalid URL with Emoji

```typescript
// Replace the routes array with this to test:
const routes = [
  { path: '', priority: '1.0', changefreq: 'daily' },
  { path: 'about', priority: '0.8', changefreq: 'weekly' },
  { path: 'üöÄbadurl/üí•test', priority: '0.5', changefreq: 'never' }, // INVALID!
  { path: 'contact', priority: '0.8', changefreq: 'monthly' },
];
```

### What Happens:
- **XML Output:** The emoji will be rendered as is in the URL
- **Browser:** May show "This page contains the following errors" with line numbers
- **Google Search Console:** Will reject the sitemap or skip invalid URLs
- **Error Type:** Invalid characters in URL (emojis must be URL-encoded)

### How to Fix:
- Remove emojis from URLs
- Use URL encoding: `encodeURIComponent()` if dynamic URLs
- Validate all URLs before adding to sitemap
- Use only valid URL characters: a-z, A-Z, 0-9, hyphen, underscore

---

## ‚ö†Ô∏è Test 2: Missing Closing Tag

```typescript
// In the sitemap generation, remove one closing tag:
const sitemap = `<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
${routes.map(route => `  <url>
    <loc>${baseUrl}/${route.path}</loc>
    <lastmod>${currentDate}</lastmod>
    <changefreq>${route.changefreq}</changefreq>
    <priority>${route.priority}</priority>
  <!-- MISSING </url> HERE! -->
  `).join('\n')}
</urlset>`;
```

### What Happens:
- **Browser:** Shows XML parsing error message like:
  - "XML Parsing Error: mismatched tag. Expected: </url>"
  - "error on line 23 at column 3"
- **View Source:** Raw XML shows missing tag
- **Google Search Console:** Sitemap rejected - "XML parsing error"
- **Effect:** Entire sitemap becomes unusable

### How to Fix:
- Ensure every opening tag has a closing tag
- Use a template literal carefully with proper nesting
- Test XML with online validators
- Use XML formatting tools to catch errors

---

## ‚ö†Ô∏è Test 3: Missing Content-Type Header

```typescript
// Remove the Content-Type header:
return new NextResponse(sitemap, {
  status: 200,
  headers: {
    // 'Content-Type': 'application/xml', // COMMENTED OUT!
    'Cache-Control': 'public, s-maxage=86400, stale-while-revalidate',
  },
});
```

### What Happens:
- **Browser Display:** 
  - Renders as **plain text** instead of formatted XML
  - Shows as one long string without structure
  - No XML syntax highlighting
  - No collapsible nodes
- **View Source:** Shows XML but browser doesn't recognize it as XML
- **Google Search Console:** May still work (checks content, not just headers)
- **SEO Impact:** Low - crawlers read content regardless
- **User Experience:** Poor - looks unprofessional

### How to Fix:
- Always set `Content-Type: application/xml` for XML content
- Can also use `text/xml` (older, but works)
- Add charset: `application/xml; charset=utf-8` for best practices

---

## ‚ö†Ô∏è Test 4: Duplicate URLs

```typescript
// Add the same URL twice:
const routes = [
  { path: '', priority: '1.0', changefreq: 'daily' },
  { path: 'about', priority: '0.8', changefreq: 'weekly' },
  { path: 'listings', priority: '0.9', changefreq: 'daily' },
  { path: 'listings', priority: '0.7', changefreq: 'weekly' }, // DUPLICATE!
  { path: 'contact', priority: '0.8', changefreq: 'monthly' },
];
```

### What Happens:
- **Browser Display:** XML renders fine (no syntax error)
- **Google Search Console:** 
  - Shows warning: "Duplicate URLs in sitemap"
  - May only index the first occurrence
  - Crawl budget potentially wasted
- **Search Ranking:** No direct penalty, but inefficient
- **Best Practice Violation:** Sitemaps should have unique URLs only

### How to Fix:
```typescript
// Use Set to ensure unique URLs:
const uniqueRoutes = Array.from(
  new Map(routes.map(route => [route.path, route])).values()
);

// Or filter duplicates:
const uniqueRoutes = routes.filter((route, index, self) =>
  index === self.findIndex((r) => r.path === route.path)
);
```

---

## üß™ How to Test Each Scenario

1. **Backup the working route.ts:**
   ```bash
   cp app/sitemap.xml/route.ts app/sitemap.xml/route.ts.backup
   ```

2. **Apply one of the broken examples above**

3. **Restart your dev server:**
   ```bash
   # Stop the server (Ctrl+C)
   npm run dev
   ```

4. **Visit:** http://localhost:3000/sitemap.xml

5. **Observe the error/behavior**

6. **Restore the working version:**
   ```bash
   cp app/sitemap.xml/route.ts.backup app/sitemap.xml/route.ts
   ```

---

## üîç Additional Validation Tools

### Online XML Validators:
- https://www.xmlvalidation.com/
- https://validator.w3.org/feed/
- https://www.xml-sitemaps.com/validate-xml-sitemap.html

### Test in Google Search Console:
1. Go to Search Console
2. Navigate to Sitemaps
3. Submit: https://yourdomain.com/sitemap.xml
4. Check for errors/warnings

### Command Line Testing:
```bash
# Validate XML structure
curl http://localhost:3000/sitemap.xml | xmllint --noout -

# View formatted XML
curl http://localhost:3000/sitemap.xml | xmllint --format -

# Check HTTP headers
curl -I http://localhost:3000/sitemap.xml
```

---

## ‚úÖ Best Practices for Production

1. **Always validate URLs** before adding to sitemap
2. **Use proper Content-Type** header
3. **Avoid duplicate URLs** with Set or Map
4. **Update lastmod** when content changes
5. **Use appropriate priorities** (0.0 to 1.0)
6. **Set realistic changefreq** values
7. **Consider splitting** large sitemaps (>50,000 URLs)
8. **Add to robots.txt:**
   ```
   Sitemap: https://yourdomain.com/sitemap.xml
   ```
9. **Submit to search engines** (Google, Bing)
10. **Monitor errors** in Search Console

---

## üìö Sitemap XML Standards

### Valid Priority Values:
- 1.0 = Highest priority (homepage)
- 0.8 = High (important pages)
- 0.5 = Medium (standard pages)
- 0.3 = Low (archives, old content)
- 0.0 = Lowest (optional pages)

### Valid Changefreq Values:
- `always` = Changes every access
- `hourly` = Hourly updates
- `daily` = Daily updates
- `weekly` = Weekly updates
- `monthly` = Monthly updates
- `yearly` = Yearly updates
- `never` = Archived content

### URL Requirements:
- Must be absolute URLs (include protocol and domain)
- Must use proper URL encoding
- Maximum 2,048 characters
- Must be accessible by Googlebot
- Should return 200 status code

